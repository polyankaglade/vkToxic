{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем мета-файл (дважды, потому что один из них будем менять, а второй референсить). Можно было бы сделать более логично, но я почему-то решила так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../preprocess/meta.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "with open('../preprocess/meta.json', 'r') as f:\n",
    "    original_meta = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем файл с обработанными данными, заменяем все пустые ячейки на `none`. Откуда пустые ячейки? Они возникают в вариантах препроцессинга, где используется удаление стоп-слов и/или удаление эмоджи (например, когда комментарий изначально состоял только из эмоджи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, index_col=0, sep='\\t')\n",
    "    print(f'loaded from {filepath}')\n",
    "    print(df['разметка'].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from ../Data/data_preprocessed.tsv\n",
      "negative    491\n",
      "positive    410\n",
      "neutral     357\n",
      "speech      213\n",
      "Name: разметка, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = load_data('../Data/data_preprocessed.tsv')\n",
    "data.fillna('none',  inplace=True)\n",
    "assert data.isnull().values.any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для кодирования разметки в числовые классы. **NB**: классы `neutral` и `speech` объединяются (чтобы было больше данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labeling(label):\n",
    "    if label == 'negative':\n",
    "        label_id = -1\n",
    "    elif label == 'neutral':\n",
    "        label_id = 0\n",
    "    elif label == 'positive':\n",
    "        label_id = 1\n",
    "    elif label == 'speech':\n",
    "        label_id = 0\n",
    "        \n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая обычная tf-idf векторизация, т.к. данных мало и объем вокабуляра не превышает 5к слов. Для ускорения работы используется `analyzer=str.split`, чтобы отключить встроенную токенизацию (т.к. все наши данные и так токенизированны через пробел)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, col_name):\n",
    "    y = data['разметка'].apply(encode_labeling)\n",
    "    \n",
    "    corpus = data[col_name]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(analyzer=str.split)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1471, 4821)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_id = str(0)\n",
    "X, y = transform_data(data, prep_id)\n",
    "print(X.shape)\n",
    "original_meta[prep_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы решили сравнить 5 алгоритмов класификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "SEED = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pred(X_train, X_test, y_train, y_test, clf=None):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print_report = classification_report(y_test, pred)\n",
    "    report = classification_report(y_test, pred, output_dict=True)\n",
    "    #print(print_report)\n",
    "    return pred, print_report, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гридсерч используется ниже, уже после определения наиболее удачной модели и препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_pred(X_train, X_test, y_train, y_test, clf=None, params={}, cv=5):\n",
    "    grid = GridSearchCV(clf, params, cv=cv)\n",
    "    grid.fit(X_train, y_train)\n",
    "    #print(grid.best_params_)\n",
    "    \n",
    "    best = grid.best_estimator_\n",
    "    \n",
    "    best.fit(X_train, y_train)\n",
    "    pred = best.predict(X_test)\n",
    "    print_report = classification_report(y_test, pred)\n",
    "    report = classification_report(y_test, pred, output_dict=True)\n",
    "    #print(print_report)\n",
    "    \n",
    "    return best, pred, print_report, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама функция которая обучает все модели и возвращает отчет с метриками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(X_train, X_test, y_train, y_test, log=False):\n",
    "    \n",
    "    clf_logreg = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "    clf_sgd = SGDClassifier(random_state=SEED)\n",
    "    clf_forest = RandomForestClassifier(random_state=SEED)\n",
    "    clf_bayes = MultinomialNB()\n",
    "    clf_xgboost = XGBClassifier()\n",
    "\n",
    "    clfs = {'logreg': {'model': clf_logreg, 'report': {}},\n",
    "            'sgd': {'model': clf_sgd, 'report': {}},\n",
    "            'forest': {'model': clf_forest, 'report': {}}, \n",
    "            'bayes':  {'model': clf_bayes,  'report': {}},\n",
    "            'xgboost':  {'model': clf_xgboost,  'report': {}}\n",
    "           }\n",
    "    \n",
    "    for name, clf in clfs.items():\n",
    "        model = clf['model']\n",
    "        _, print_report, report = fit_pred(X_train, X_test, y_train, y_test, clf=model)\n",
    "        clfs[name]['report'] = report\n",
    "        \n",
    "        \n",
    "        if log:\n",
    "            print(name.upper())\n",
    "            print(print_report)\n",
    "        \n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования на данных, заданных выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGREG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.65      0.71       148\n",
      "           0       0.65      0.87      0.74       171\n",
      "           1       0.90      0.66      0.76       123\n",
      "\n",
      "    accuracy                           0.74       442\n",
      "   macro avg       0.78      0.73      0.74       442\n",
      "weighted avg       0.77      0.74      0.74       442\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.68      0.72       148\n",
      "           0       0.66      0.78      0.72       171\n",
      "           1       0.83      0.73      0.78       123\n",
      "\n",
      "    accuracy                           0.73       442\n",
      "   macro avg       0.75      0.73      0.74       442\n",
      "weighted avg       0.74      0.73      0.73       442\n",
      "\n",
      "FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.61      0.69       148\n",
      "           0       0.62      0.85      0.72       171\n",
      "           1       0.84      0.62      0.71       123\n",
      "\n",
      "    accuracy                           0.71       442\n",
      "   macro avg       0.75      0.70      0.71       442\n",
      "weighted avg       0.74      0.71      0.71       442\n",
      "\n",
      "BAYES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.68      0.74       148\n",
      "           0       0.64      0.86      0.73       171\n",
      "           1       0.92      0.64      0.76       123\n",
      "\n",
      "    accuracy                           0.74       442\n",
      "   macro avg       0.79      0.73      0.74       442\n",
      "weighted avg       0.77      0.74      0.74       442\n",
      "\n",
      "XGBOOST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.66      0.68       148\n",
      "           0       0.61      0.74      0.67       171\n",
      "           1       0.80      0.63      0.71       123\n",
      "\n",
      "    accuracy                           0.68       442\n",
      "   macro avg       0.70      0.68      0.68       442\n",
      "weighted avg       0.69      0.68      0.68       442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "report = try_models(X_train, X_test, y_train, y_test, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted avg f1-score\n",
      "\n",
      "LOGREG\t0.7374347908073318\n",
      "SGD\t0.7340997854448016\n",
      "FOREST\t0.7071838275544589\n",
      "BAYES\t0.7410735405762653\n",
      "XGBOOST\t0.6822678301646522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('weighted avg f1-score\\n')\n",
    "\n",
    "for name, clf in report.items():\n",
    "    print(f\"{name.upper()}\\t{clf['report']['weighted avg']['f1-score']}\")\n",
    "          \n",
    "original_meta[prep_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей с базовыми параметрами и всех препроцессингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь обучается и замеряется кач-во 960 моделей (за ~8 минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbea441190c4c4cb0a13d2e0b06e82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for m_id, m in tqdm(meta.items()):\n",
    "    X, y = transform_data(data, m_id)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "    \n",
    "    reports = try_models(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    meta[m_id]['reports'] = reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если есть файл, мжно подгрузить его\n",
    "\n",
    "with open('compare_meta.pickle', 'rb') as f:\n",
    "    meta_from_file = pickle.load(f)\n",
    "    \n",
    "# meta = meta_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики выбрали weighted average f1-score, вырезаем только его, чтобы можно было внимательнее посмотреть на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weighted_fs = []\n",
    "preps = []\n",
    "models = []\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    #print(original_meta[m_id])\n",
    "    \n",
    "    for name, clf in m['reports'].items():\n",
    "        score = clf['report']['weighted avg']['f1-score']\n",
    "        \n",
    "        weighted_fs.append(score)\n",
    "        preps.append(m_id)\n",
    "        models.append(name)\n",
    "        #print(f\"{name.upper()}\\t{score}\")\n",
    "        \n",
    "    #print('\\n===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все варианты с метрикой выше `0.75`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\tsgd\t0.779170661715591\n",
      "86\tsgd\t0.7720163909018399\n",
      "55\tlogreg\t0.7717005314453232\n",
      "87\tlogreg\t0.7717005314453232\n",
      "23\tlogreg\t0.7717005314453232\n",
      "55\tsgd\t0.7706759599004663\n",
      "85\tlogreg\t0.7691577909208065\n",
      "20\tsgd\t0.7690593212382701\n",
      "87\tsgd\t0.7682864093475529\n",
      "52\tsgd\t0.7672515969379039\n",
      "48\tsgd\t0.7669885503015509\n",
      "21\tlogreg\t0.7668862890449263\n",
      "53\tlogreg\t0.7668862890449263\n",
      "51\tlogreg\t0.7665839819182566\n",
      "19\tlogreg\t0.7665839819182566\n",
      "83\tlogreg\t0.7665839819182566\n",
      "176\tsgd\t0.76604592866399\n",
      "22\tsgd\t0.7655973947668203\n",
      "55\tforest\t0.7652950087029121\n",
      "117\tlogreg\t0.7645595425092476\n",
      "181\tlogreg\t0.7645595425092476\n",
      "149\tlogreg\t0.7645595425092476\n",
      "81\tlogreg\t0.7641877753760317\n",
      "49\tlogreg\t0.7641877753760317\n",
      "17\tlogreg\t0.7641877753760317\n",
      "85\tsgd\t0.7635909031733173\n",
      "149\tbayes\t0.7633686569128357\n",
      "181\tbayes\t0.7633686569128357\n",
      "117\tbayes\t0.7633686569128357\n",
      "49\tsgd\t0.7630524487419506\n",
      "119\tlogreg\t0.7625550125498421\n",
      "151\tlogreg\t0.7625550125498421\n",
      "183\tlogreg\t0.7625550125498421\n",
      "80\tsgd\t0.7621709242482197\n",
      "54\tlogreg\t0.7620804534831686\n",
      "86\tlogreg\t0.7620804534831686\n",
      "22\tlogreg\t0.7620804534831686\n",
      "52\tlogreg\t0.7618360028289387\n",
      "20\tlogreg\t0.7618360028289387\n",
      "84\tlogreg\t0.7618360028289387\n",
      "71\tlogreg\t0.761670253107071\n",
      "7\tlogreg\t0.761670253107071\n",
      "39\tlogreg\t0.761670253107071\n",
      "183\tbayes\t0.7615550364420896\n",
      "151\tbayes\t0.7615550364420896\n",
      "119\tbayes\t0.7615550364420896\n",
      "54\tsgd\t0.7612164217330719\n",
      "84\tsgd\t0.7608654391132358\n",
      "5\tlogreg\t0.7590430268630961\n",
      "37\tlogreg\t0.7590430268630961\n",
      "69\tlogreg\t0.7590430268630961\n",
      "21\tsgd\t0.7588730736961566\n",
      "17\tsgd\t0.7583581909451448\n",
      "116\tlogreg\t0.7579473700345579\n",
      "118\tsgd\t0.7573576806093847\n",
      "23\tsgd\t0.7569036018838555\n",
      "53\tsgd\t0.756849550561315\n",
      "114\tsgd\t0.7561136113855315\n",
      "148\tlogreg\t0.7556475239194751\n",
      "180\tlogreg\t0.7556475239194751\n",
      "80\tlogreg\t0.7553879457604467\n",
      "48\tlogreg\t0.7553879457604467\n",
      "16\tlogreg\t0.7553879457604467\n",
      "67\tlogreg\t0.7552642582571611\n",
      "35\tlogreg\t0.7552642582571611\n",
      "3\tlogreg\t0.7552642582571611\n",
      "16\tsgd\t0.7548980558049776\n",
      "182\tlogreg\t0.7536100272504421\n",
      "118\tlogreg\t0.7536100272504421\n",
      "150\tlogreg\t0.7536100272504421\n",
      "37\tsgd\t0.7535338382844777\n",
      "146\tsgd\t0.7533458915808308\n",
      "83\tsgd\t0.7523905065582697\n",
      "147\tlogreg\t0.7522802594021671\n",
      "115\tlogreg\t0.7522802594021671\n",
      "83\tforest\t0.7522041069810573\n",
      "85\tforest\t0.7521599301250624\n",
      "113\tbayes\t0.7517689594182706\n",
      "177\tbayes\t0.7517689594182706\n",
      "145\tbayes\t0.7517689594182706\n",
      "101\tforest\t0.7511171775102093\n",
      "33\tlogreg\t0.750818889308931\n",
      "1\tlogreg\t0.750818889308931\n",
      "65\tlogreg\t0.750818889308931\n",
      "50\tlogreg\t0.7507252686129084\n",
      "82\tlogreg\t0.7507252686129084\n",
      "18\tlogreg\t0.7507252686129084\n",
      "148\tsgd\t0.7500226407520483\n",
      "181\tsgd\t0.750021728395085\n"
     ]
    }
   ],
   "source": [
    "top_prep = []\n",
    "top_model = []\n",
    "\n",
    "for i in np.argsort(weighted_fs)[::-1]:\n",
    "    if weighted_fs[i] < 0.75:\n",
    "        break\n",
    "    top_prep.append(preps[i])\n",
    "    top_model.append(models[i])\n",
    "    print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разброс значений для наилучшего алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\tsgd\t0.779170661715591\n",
      "86\tsgd\t0.7720163909018399\n",
      "55\tsgd\t0.7706759599004663\n",
      "20\tsgd\t0.7690593212382701\n",
      "87\tsgd\t0.7682864093475529\n",
      "52\tsgd\t0.7672515969379039\n",
      "48\tsgd\t0.7669885503015509\n",
      "176\tsgd\t0.76604592866399\n",
      "22\tsgd\t0.7655973947668203\n",
      "85\tsgd\t0.7635909031733173\n",
      "49\tsgd\t0.7630524487419506\n",
      "80\tsgd\t0.7621709242482197\n",
      "54\tsgd\t0.7612164217330719\n",
      "84\tsgd\t0.7608654391132358\n",
      "21\tsgd\t0.7588730736961566\n",
      "17\tsgd\t0.7583581909451448\n",
      "118\tsgd\t0.7573576806093847\n",
      "23\tsgd\t0.7569036018838555\n",
      "53\tsgd\t0.756849550561315\n",
      "114\tsgd\t0.7561136113855315\n",
      "16\tsgd\t0.7548980558049776\n",
      "37\tsgd\t0.7535338382844777\n",
      "146\tsgd\t0.7533458915808308\n",
      "83\tsgd\t0.7523905065582697\n",
      "148\tsgd\t0.7500226407520483\n",
      "181\tsgd\t0.750021728395085\n",
      "112\tsgd\t0.7496177819845157\n",
      "57\tsgd\t0.7494096383871373\n",
      "125\tsgd\t0.7476702711581116\n",
      "88\tsgd\t0.7476496590105673\n",
      "61\tsgd\t0.747513379537516\n",
      "177\tsgd\t0.7474977189292923\n",
      "144\tsgd\t0.7472289075662439\n",
      "178\tsgd\t0.7464083205702481\n",
      "182\tsgd\t0.7463898403753455\n",
      "69\tsgd\t0.7461486258199062\n",
      "117\tsgd\t0.745793555410885\n",
      "116\tsgd\t0.7457820196309313\n",
      "149\tsgd\t0.7457754031982875\n",
      "185\tsgd\t0.7450934089535405\n",
      "89\tsgd\t0.7442810298993774\n",
      "135\tsgd\t0.7441057790389694\n",
      "82\tsgd\t0.7438768821531613\n",
      "5\tsgd\t0.74364922066294\n",
      "180\tsgd\t0.7436255469672031\n",
      "151\tsgd\t0.7431032631741511\n",
      "145\tsgd\t0.7430838464940632\n",
      "31\tsgd\t0.7428419664799755\n",
      "153\tsgd\t0.7428295831356758\n",
      "113\tsgd\t0.7428091378381354\n",
      "50\tsgd\t0.7417117079515263\n",
      "18\tsgd\t0.7417117079515263\n",
      "7\tsgd\t0.7414488132236257\n",
      "29\tsgd\t0.7397280988238726\n",
      "71\tsgd\t0.7393898197015916\n",
      "150\tsgd\t0.7392428857239434\n",
      "3\tsgd\t0.737878359101157\n",
      "35\tsgd\t0.737878359101157\n",
      "25\tsgd\t0.7372243869395659\n",
      "115\tsgd\t0.736650941435915\n",
      "119\tsgd\t0.7364674408793818\n",
      "51\tsgd\t0.7358022932244597\n",
      "19\tsgd\t0.7358022932244597\n",
      "63\tsgd\t0.7355806141188049\n",
      "95\tsgd\t0.7353288444305133\n",
      "1\tsgd\t0.7348142968135746\n",
      "183\tsgd\t0.7344866344450631\n",
      "191\tsgd\t0.7340997854448016\n",
      "127\tsgd\t0.7340260154371122\n",
      "152\tsgd\t0.7339663521034695\n",
      "93\tsgd\t0.7336320428525954\n",
      "65\tsgd\t0.7328674138517419\n",
      "39\tsgd\t0.7328346237556914\n",
      "167\tsgd\t0.7327490916822168\n",
      "24\tsgd\t0.7322293045594426\n",
      "101\tsgd\t0.7322030810495805\n",
      "147\tsgd\t0.7319627348624863\n",
      "159\tsgd\t0.7317640697939501\n",
      "103\tsgd\t0.7304608510599394\n",
      "33\tsgd\t0.730389841073035\n",
      "133\tsgd\t0.729810624935196\n",
      "56\tsgd\t0.7297961511179626\n",
      "184\tsgd\t0.7295548955066382\n",
      "62\tsgd\t0.7293898201517458\n",
      "157\tsgd\t0.7293716066780204\n",
      "67\tsgd\t0.7287757772238129\n",
      "120\tsgd\t0.7276883388677202\n",
      "121\tsgd\t0.7270411944771237\n",
      "189\tsgd\t0.7268369607594865\n",
      "165\tsgd\t0.7259600994378712\n",
      "30\tsgd\t0.7252905642314177\n",
      "179\tsgd\t0.7252083829902622\n",
      "158\tsgd\t0.7249100752658626\n",
      "126\tsgd\t0.724704073771796\n",
      "156\tsgd\t0.7246231905830443\n",
      "28\tsgd\t0.7220954159073543\n",
      "59\tsgd\t0.7220394660704031\n",
      "27\tsgd\t0.7220394660704031\n",
      "173\tsgd\t0.7217817706597229\n",
      "15\tsgd\t0.7216246001445651\n",
      "131\tsgd\t0.7213975381862376\n",
      "99\tsgd\t0.7213975381862376\n",
      "45\tsgd\t0.7209600963256205\n",
      "190\tsgd\t0.7208277550296853\n",
      "163\tsgd\t0.7194684143894683\n",
      "129\tsgd\t0.7188903214766679\n",
      "60\tsgd\t0.7186644286268852\n",
      "91\tsgd\t0.7183363337063527\n",
      "94\tsgd\t0.71828227526791\n",
      "123\tsgd\t0.718257984564242\n",
      "92\tsgd\t0.7180926832753196\n",
      "124\tsgd\t0.7176990926884376\n",
      "109\tsgd\t0.7176746129190016\n",
      "97\tsgd\t0.7170175238556584\n",
      "134\tsgd\t0.7165500674025811\n",
      "111\tsgd\t0.7154126563546517\n",
      "13\tsgd\t0.7148236157473424\n",
      "141\tsgd\t0.7147125660372053\n",
      "161\tsgd\t0.7143710251242857\n",
      "77\tsgd\t0.7140206575368737\n",
      "188\tsgd\t0.7133566812386843\n",
      "175\tsgd\t0.713001241889549\n",
      "105\tsgd\t0.7120641928446237\n",
      "11\tsgd\t0.7099287077457405\n",
      "43\tsgd\t0.7099287077457405\n",
      "79\tsgd\t0.7097959239486384\n",
      "75\tsgd\t0.7094994009502485\n",
      "187\tsgd\t0.7091701130410807\n",
      "36\tsgd\t0.7091614060978283\n",
      "155\tsgd\t0.7088806975438784\n",
      "143\tsgd\t0.7085777016293805\n",
      "68\tsgd\t0.7083873721063991\n",
      "137\tsgd\t0.7075546247415835\n",
      "9\tsgd\t0.707342414854743\n",
      "47\tsgd\t0.7070380696191257\n",
      "6\tsgd\t0.7067415749682517\n",
      "169\tsgd\t0.7060635446360772\n",
      "122\tsgd\t0.7054916632567444\n",
      "58\tsgd\t0.7042691307007113\n",
      "26\tsgd\t0.7042691307007113\n",
      "4\tsgd\t0.7034587348957188\n",
      "186\tsgd\t0.7030205073234655\n",
      "100\tsgd\t0.7025064806766622\n",
      "38\tsgd\t0.7023349644890797\n",
      "102\tsgd\t0.7018393615795936\n",
      "41\tsgd\t0.700675106189447\n",
      "73\tsgd\t0.7006706831214461\n",
      "64\tsgd\t0.7006319905455201\n",
      "132\tsgd\t0.6986340276622817\n",
      "166\tsgd\t0.6982285554497267\n",
      "164\tsgd\t0.6980526895598919\n",
      "154\tsgd\t0.6966643972286111\n",
      "96\tsgd\t0.696184112826491\n",
      "8\tsgd\t0.6961360157036949\n",
      "32\tsgd\t0.6954065927064962\n",
      "70\tsgd\t0.6951463735694235\n",
      "90\tsgd\t0.6944463928198675\n",
      "72\tsgd\t0.6940017874792528\n",
      "14\tsgd\t0.6920913373240603\n",
      "12\tsgd\t0.691883471380212\n",
      "44\tsgd\t0.6917490884428696\n",
      "0\tsgd\t0.6915339984229573\n",
      "40\tsgd\t0.6914884576904528\n",
      "139\tsgd\t0.6881858126990943\n",
      "107\tsgd\t0.6881858126990943\n",
      "171\tsgd\t0.6881858126990943\n",
      "2\tsgd\t0.6879497036464636\n",
      "34\tsgd\t0.6879497036464636\n",
      "104\tsgd\t0.6877503301651908\n",
      "76\tsgd\t0.6866581269418931\n",
      "110\tsgd\t0.6852989577399886\n",
      "172\tsgd\t0.6849860478739758\n",
      "160\tsgd\t0.6844897794138968\n",
      "46\tsgd\t0.6842559720811516\n",
      "162\tsgd\t0.683707076268303\n",
      "128\tsgd\t0.6827663851988032\n",
      "66\tsgd\t0.6819550722260317\n",
      "78\tsgd\t0.6818118452799159\n",
      "108\tsgd\t0.6804828563789808\n",
      "140\tsgd\t0.6783218005436586\n",
      "174\tsgd\t0.6761325907329907\n",
      "42\tsgd\t0.6754594878857126\n",
      "10\tsgd\t0.6754594878857126\n",
      "142\tsgd\t0.6738907561131133\n",
      "74\tsgd\t0.6716093112997845\n",
      "136\tsgd\t0.6694673583606937\n",
      "168\tsgd\t0.6693633066507629\n",
      "98\tsgd\t0.6678548247114993\n",
      "130\tsgd\t0.6678548247114993\n",
      "170\tsgd\t0.6582737476412338\n",
      "138\tsgd\t0.6460565430488242\n",
      "106\tsgd\t0.6460565430488242\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(weighted_fs)[::-1]:\n",
    "    if models[i] == 'sgd':\n",
    "        print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что лучший результат дает препроцессинг с заменой именованных сущностей, заменой мата на плейсходер и лемматизацией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'replace',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['81']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А худший результат получается при удалении всего, что можно, и без нормализации (нет ни лемматизации, ни замены мата):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'yes',\n",
       " 'ner_processing': 'del',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'yes',\n",
       " 'emojis_processing': 'del',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['138']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим внимательнее на варианты с результатами `> 0.73`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logreg', 50), ('sgd', 26), ('bayes', 9), ('forest', 4)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_models = Counter(top_model).most_common()\n",
    "c_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('55', 3),\n",
       " ('85', 3),\n",
       " ('83', 3),\n",
       " ('181', 3),\n",
       " ('81', 2),\n",
       " ('86', 2),\n",
       " ('87', 2),\n",
       " ('23', 2),\n",
       " ('20', 2),\n",
       " ('52', 2),\n",
       " ('48', 2),\n",
       " ('21', 2),\n",
       " ('53', 2),\n",
       " ('22', 2),\n",
       " ('117', 2),\n",
       " ('149', 2),\n",
       " ('49', 2),\n",
       " ('17', 2),\n",
       " ('119', 2),\n",
       " ('151', 2),\n",
       " ('183', 2),\n",
       " ('80', 2),\n",
       " ('54', 2),\n",
       " ('84', 2),\n",
       " ('37', 2),\n",
       " ('118', 2),\n",
       " ('148', 2),\n",
       " ('16', 2)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, f) for n, f in Counter(top_prep).most_common() if f > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'replace',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'del',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['83']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'del',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'label',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'replace',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'replace',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['85']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего изучения на всякий случай сохраняем все результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_meta = {}\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    json_meta[m_id] = {'prep': {},\n",
    "                       'reports': {'logreg': {},\n",
    "                                   'sgd': {},\n",
    "                                   'forest': {}, \n",
    "                                   'bayes':  {},\n",
    "                                   'xgboost':  {}}\n",
    "                      }\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    json_meta[m_id]['prep'] = original_meta[m_id]\n",
    "    for name, clf in m['reports'].items():\n",
    "        json_meta[m_id]['reports'][name] = clf['report']\n",
    "\n",
    "with open('compare.json', 'w') as f:\n",
    "    json.dump(json_meta, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример как выглядит первый из 192 элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prep': {'punctuation_deletion': 'no',\n",
       "  'ner_processing': 'no',\n",
       "  'lemmatization': 'no',\n",
       "  'stopwords_deletion': 'no',\n",
       "  'emojis_processing': 'no',\n",
       "  'vulgar_processing': 'no'},\n",
       " 'reports': {'logreg': {'-1': {'precision': 0.7843137254901961,\n",
       "    'recall': 0.5405405405405406,\n",
       "    'f1-score': 0.6399999999999999,\n",
       "    'support': 148},\n",
       "   '0': {'precision': 0.6419213973799127,\n",
       "    'recall': 0.8596491228070176,\n",
       "    'f1-score': 0.735,\n",
       "    'support': 171},\n",
       "   '1': {'precision': 0.8018018018018018,\n",
       "    'recall': 0.7235772357723578,\n",
       "    'f1-score': 0.7606837606837608,\n",
       "    'support': 123},\n",
       "   'accuracy': 0.7149321266968326,\n",
       "   'macro avg': {'precision': 0.742678974890637,\n",
       "    'recall': 0.7079222997066387,\n",
       "    'f1-score': 0.7118945868945868,\n",
       "    'support': 442},\n",
       "   'weighted avg': {'precision': 0.7340918822310762,\n",
       "    'recall': 0.7149321266968326,\n",
       "    'f1-score': 0.710337336117879,\n",
       "    'support': 442}},\n",
       "  'sgd': {'-1': {'precision': 0.7096774193548387,\n",
       "    'recall': 0.5945945945945946,\n",
       "    'f1-score': 0.6470588235294118,\n",
       "    'support': 148},\n",
       "   '0': {'precision': 0.6381909547738693,\n",
       "    'recall': 0.7426900584795322,\n",
       "    'f1-score': 0.6864864864864865,\n",
       "    'support': 171},\n",
       "   '1': {'precision': 0.7647058823529411,\n",
       "    'recall': 0.7398373983739838,\n",
       "    'f1-score': 0.7520661157024795,\n",
       "    'support': 123},\n",
       "   'accuracy': 0.6923076923076923,\n",
       "   'macro avg': {'precision': 0.7041914188272164,\n",
       "    'recall': 0.6923740171493701,\n",
       "    'f1-score': 0.6952038085727926,\n",
       "    'support': 442},\n",
       "   'weighted avg': {'precision': 0.6973342417652931,\n",
       "    'recall': 0.6923076923076923,\n",
       "    'f1-score': 0.6915339984229573,\n",
       "    'support': 442}},\n",
       "  'forest': {'-1': {'precision': 0.7410714285714286,\n",
       "    'recall': 0.5608108108108109,\n",
       "    'f1-score': 0.6384615384615385,\n",
       "    'support': 148},\n",
       "   '0': {'precision': 0.6822916666666666,\n",
       "    'recall': 0.7660818713450293,\n",
       "    'f1-score': 0.7217630853994491,\n",
       "    'support': 171},\n",
       "   '1': {'precision': 0.6594202898550725,\n",
       "    'recall': 0.7398373983739838,\n",
       "    'f1-score': 0.6973180076628351,\n",
       "    'support': 123},\n",
       "   'accuracy': 0.6900452488687783,\n",
       "   'macro avg': {'precision': 0.6942611283643894,\n",
       "    'recall': 0.6889100268432746,\n",
       "    'f1-score': 0.6858475438412742,\n",
       "    'support': 442},\n",
       "   'weighted avg': {'precision': 0.6956089187347181,\n",
       "    'recall': 0.6900452488687783,\n",
       "    'f1-score': 0.6870676702220413,\n",
       "    'support': 442}},\n",
       "  'bayes': {'-1': {'precision': 0.8181818181818182,\n",
       "    'recall': 0.4864864864864865,\n",
       "    'f1-score': 0.6101694915254238,\n",
       "    'support': 148},\n",
       "   '0': {'precision': 0.5578947368421052,\n",
       "    'recall': 0.9298245614035088,\n",
       "    'f1-score': 0.6973684210526315,\n",
       "    'support': 171},\n",
       "   '1': {'precision': 0.9565217391304348,\n",
       "    'recall': 0.5365853658536586,\n",
       "    'f1-score': 0.6875000000000001,\n",
       "    'support': 123},\n",
       "   'accuracy': 0.6719457013574661,\n",
       "   'macro avg': {'precision': 0.7775327647181195,\n",
       "    'recall': 0.6509654712478846,\n",
       "    'f1-score': 0.6650126375260185,\n",
       "    'support': 442},\n",
       "   'weighted avg': {'precision': 0.7559798258007977,\n",
       "    'recall': 0.6719457013574661,\n",
       "    'f1-score': 0.6654243998772912,\n",
       "    'support': 442}},\n",
       "  'xgboost': {'-1': {'precision': 0.6904761904761905,\n",
       "    'recall': 0.5878378378378378,\n",
       "    'f1-score': 0.6350364963503649,\n",
       "    'support': 148},\n",
       "   '0': {'precision': 0.6565656565656566,\n",
       "    'recall': 0.7602339181286549,\n",
       "    'f1-score': 0.7046070460704608,\n",
       "    'support': 171},\n",
       "   '1': {'precision': 0.7288135593220338,\n",
       "    'recall': 0.6991869918699187,\n",
       "    'f1-score': 0.7136929460580914,\n",
       "    'support': 123},\n",
       "   'accuracy': 0.6855203619909502,\n",
       "   'macro avg': {'precision': 0.6919518021212937,\n",
       "    'recall': 0.6824195826121372,\n",
       "    'f1-score': 0.684445496159639,\n",
       "    'support': 442},\n",
       "   'weighted avg': {'precision': 0.6880255005878136,\n",
       "    'recall': 0.6855203619909502,\n",
       "    'f1-score': 0.6838403590566697,\n",
       "    'support': 442}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_meta['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На еще более всякий случай сохраняю всю мету вместе с моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('compare_meta.pickle', 'wb') as f:\n",
    "    pickle.dump(meta, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример как выглядит первый из 192 элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'no',\n",
       " 'reports': {'logreg': {'model': LogisticRegression(random_state=67, solver='liblinear'),\n",
       "   'report': {'-1': {'precision': 0.7843137254901961,\n",
       "     'recall': 0.5405405405405406,\n",
       "     'f1-score': 0.6399999999999999,\n",
       "     'support': 148},\n",
       "    '0': {'precision': 0.6419213973799127,\n",
       "     'recall': 0.8596491228070176,\n",
       "     'f1-score': 0.735,\n",
       "     'support': 171},\n",
       "    '1': {'precision': 0.8018018018018018,\n",
       "     'recall': 0.7235772357723578,\n",
       "     'f1-score': 0.7606837606837608,\n",
       "     'support': 123},\n",
       "    'accuracy': 0.7149321266968326,\n",
       "    'macro avg': {'precision': 0.742678974890637,\n",
       "     'recall': 0.7079222997066387,\n",
       "     'f1-score': 0.7118945868945868,\n",
       "     'support': 442},\n",
       "    'weighted avg': {'precision': 0.7340918822310762,\n",
       "     'recall': 0.7149321266968326,\n",
       "     'f1-score': 0.710337336117879,\n",
       "     'support': 442}}},\n",
       "  'sgd': {'model': SGDClassifier(random_state=67),\n",
       "   'report': {'-1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.5945945945945946,\n",
       "     'f1-score': 0.6470588235294118,\n",
       "     'support': 148},\n",
       "    '0': {'precision': 0.6381909547738693,\n",
       "     'recall': 0.7426900584795322,\n",
       "     'f1-score': 0.6864864864864865,\n",
       "     'support': 171},\n",
       "    '1': {'precision': 0.7647058823529411,\n",
       "     'recall': 0.7398373983739838,\n",
       "     'f1-score': 0.7520661157024795,\n",
       "     'support': 123},\n",
       "    'accuracy': 0.6923076923076923,\n",
       "    'macro avg': {'precision': 0.7041914188272164,\n",
       "     'recall': 0.6923740171493701,\n",
       "     'f1-score': 0.6952038085727926,\n",
       "     'support': 442},\n",
       "    'weighted avg': {'precision': 0.6973342417652931,\n",
       "     'recall': 0.6923076923076923,\n",
       "     'f1-score': 0.6915339984229573,\n",
       "     'support': 442}}},\n",
       "  'forest': {'model': RandomForestClassifier(random_state=67),\n",
       "   'report': {'-1': {'precision': 0.7410714285714286,\n",
       "     'recall': 0.5608108108108109,\n",
       "     'f1-score': 0.6384615384615385,\n",
       "     'support': 148},\n",
       "    '0': {'precision': 0.6822916666666666,\n",
       "     'recall': 0.7660818713450293,\n",
       "     'f1-score': 0.7217630853994491,\n",
       "     'support': 171},\n",
       "    '1': {'precision': 0.6594202898550725,\n",
       "     'recall': 0.7398373983739838,\n",
       "     'f1-score': 0.6973180076628351,\n",
       "     'support': 123},\n",
       "    'accuracy': 0.6900452488687783,\n",
       "    'macro avg': {'precision': 0.6942611283643894,\n",
       "     'recall': 0.6889100268432746,\n",
       "     'f1-score': 0.6858475438412742,\n",
       "     'support': 442},\n",
       "    'weighted avg': {'precision': 0.6956089187347181,\n",
       "     'recall': 0.6900452488687783,\n",
       "     'f1-score': 0.6870676702220413,\n",
       "     'support': 442}}},\n",
       "  'bayes': {'model': MultinomialNB(),\n",
       "   'report': {'-1': {'precision': 0.8181818181818182,\n",
       "     'recall': 0.4864864864864865,\n",
       "     'f1-score': 0.6101694915254238,\n",
       "     'support': 148},\n",
       "    '0': {'precision': 0.5578947368421052,\n",
       "     'recall': 0.9298245614035088,\n",
       "     'f1-score': 0.6973684210526315,\n",
       "     'support': 171},\n",
       "    '1': {'precision': 0.9565217391304348,\n",
       "     'recall': 0.5365853658536586,\n",
       "     'f1-score': 0.6875000000000001,\n",
       "     'support': 123},\n",
       "    'accuracy': 0.6719457013574661,\n",
       "    'macro avg': {'precision': 0.7775327647181195,\n",
       "     'recall': 0.6509654712478846,\n",
       "     'f1-score': 0.6650126375260185,\n",
       "     'support': 442},\n",
       "    'weighted avg': {'precision': 0.7559798258007977,\n",
       "     'recall': 0.6719457013574661,\n",
       "     'f1-score': 0.6654243998772912,\n",
       "     'support': 442}}},\n",
       "  'xgboost': {'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                 colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                 importance_type='gain', interaction_constraints='',\n",
       "                 learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "                 min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                 n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                 objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "                 reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "                 tree_method='exact', validate_parameters=1, verbosity=None),\n",
       "   'report': {'-1': {'precision': 0.6904761904761905,\n",
       "     'recall': 0.5878378378378378,\n",
       "     'f1-score': 0.6350364963503649,\n",
       "     'support': 148},\n",
       "    '0': {'precision': 0.6565656565656566,\n",
       "     'recall': 0.7602339181286549,\n",
       "     'f1-score': 0.7046070460704608,\n",
       "     'support': 171},\n",
       "    '1': {'precision': 0.7288135593220338,\n",
       "     'recall': 0.6991869918699187,\n",
       "     'f1-score': 0.7136929460580914,\n",
       "     'support': 123},\n",
       "    'accuracy': 0.6855203619909502,\n",
       "    'macro avg': {'precision': 0.6919518021212937,\n",
       "     'recall': 0.6824195826121372,\n",
       "     'f1-score': 0.684445496159639,\n",
       "     'support': 442},\n",
       "    'weighted avg': {'precision': 0.6880255005878136,\n",
       "     'recall': 0.6855203619909502,\n",
       "     'f1-score': 0.6838403590566697,\n",
       "     'support': 442}}}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров\n",
    "\n",
    "В кач-ве данных возьмем препроцессинги, показавшие наилучший результат для каждой из 3 моделей с наилучшим скором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\tlogreg\t0.7717005314453232\n",
      "81\tsgd\t0.779170661715591\n",
      "149\tbayes\t0.7633686569128357\n",
      "55\tforest\t0.7652950087029121\n"
     ]
    }
   ],
   "source": [
    "for m in c_models:\n",
    "    for i in np.argsort(weighted_fs)[::-1]:\n",
    "        if models[i] == m[0]:\n",
    "            print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgd = SGDClassifier(random_state=SEED, max_iter=10000)\n",
    "params_sgd = {'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', \n",
    "                       'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "              'penalty': ['l1','l2', 'elasticnet'],\n",
    "              'fit_intercept': [True, False],\n",
    "              #'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "             }\n",
    "\n",
    "grid_logreg = LogisticRegression(random_state=SEED, max_iter=200)\n",
    "params_logreg =  {#'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "                  'C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 1000],\n",
    "                  'fit_intercept': [True, False],\n",
    "                 }\n",
    "\n",
    "grid_forest = RandomForestClassifier(random_state=SEED)\n",
    "params_forest = {'n_estimators': [10, 50, 100, 200], \n",
    "                 'max_depth': [2, 5, 10, 20, 50, 100],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "                }\n",
    "\n",
    "grid_pipeline = {\n",
    "    'sgd': {'model': grid_sgd, 'grid': params_sgd, 'prep': '81',\n",
    "            'best_model': None, 'best_params': {}, 'report': {}},\n",
    "    \n",
    "    'logreg': {'model': grid_logreg, 'grid': params_logreg, 'prep': '55',\n",
    "               'best_model': None, 'best_params': {}, 'report': {}},\n",
    "    \n",
    "    'forest': {'model': grid_forest, 'grid': params_forest, 'prep': '55',\n",
    "               'best_model': None, 'best_params': {}, 'report': {}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd weighted avg f1 = 0.7626119813231003\n",
      "fit_intercept=True\n",
      "loss=hinge\n",
      "penalty=l1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.73      0.74       148\n",
      "           0       0.73      0.80      0.77       171\n",
      "           1       0.83      0.75      0.79       123\n",
      "\n",
      "    accuracy                           0.76       442\n",
      "   macro avg       0.77      0.76      0.76       442\n",
      "weighted avg       0.77      0.76      0.76       442\n",
      "\n",
      "logreg weighted avg f1 = 0.7632298414016918\n",
      "C=1\n",
      "fit_intercept=False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.72      0.74       148\n",
      "           0       0.71      0.82      0.76       171\n",
      "           1       0.89      0.72      0.80       123\n",
      "\n",
      "    accuracy                           0.76       442\n",
      "   macro avg       0.78      0.76      0.77       442\n",
      "weighted avg       0.77      0.76      0.76       442\n",
      "\n",
      "forest weighted avg f1 = 0.7557183591521924\n",
      "criterion=gini\n",
      "max_depth=20\n",
      "n_estimators=200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.65      0.74       148\n",
      "           0       0.68      0.91      0.78       171\n",
      "           1       0.81      0.68      0.74       123\n",
      "\n",
      "    accuracy                           0.76       442\n",
      "   macro avg       0.79      0.75      0.75       442\n",
      "weighted avg       0.78      0.76      0.76       442\n",
      "\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for name, clf in grid_pipeline.items():\n",
    "    \n",
    "    X, y = transform_data(data, clf['prep'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "    \n",
    "    best, pred, print_report, report = grid_pred(X_train, X_test, y_train, y_test, \n",
    "                                                 clf=clf['model'], params=clf['grid'], cv=3)\n",
    "    \n",
    "    best_params = best.get_params()\n",
    "    grid_pipeline[name]['best_model'] = best\n",
    "    grid_pipeline[name]['best_params'] = best_params\n",
    "    grid_pipeline[name]['report'] = report\n",
    "    \n",
    "    print(f\"{name} weighted avg f1 = {report['weighted avg']['f1-score']}\")\n",
    "    for param, value in best_params.items():\n",
    "        if param in clf['grid'].keys():\n",
    "            print(f'{param}={value}')\n",
    "    print(print_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем еще поэкспериментировать с SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd\n",
      "fit_intercept=True\n",
      "loss=modified_huber\n",
      "penalty=l2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.66      0.73       148\n",
      "           0       0.71      0.82      0.76       171\n",
      "           1       0.80      0.79      0.79       123\n",
      "\n",
      "    accuracy                           0.76       442\n",
      "   macro avg       0.77      0.76      0.76       442\n",
      "weighted avg       0.77      0.76      0.76       442\n",
      "\n",
      "0.7590857064109781\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_sgd = SGDClassifier(random_state=SEED, max_iter=100000)\n",
    "\n",
    "params_sgd = {'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', \n",
    "                       'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "              'penalty': ['l1','l2', 'elasticnet'],\n",
    "              'fit_intercept': [True, False],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "             }\n",
    "\n",
    "for name, clf in grid_pipeline.items():\n",
    "    \n",
    "    if name == 'sgd':\n",
    "    \n",
    "        X, y = transform_data(data, clf['prep'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "\n",
    "        best, pred, print_report, report = grid_pred(X_train, X_test, y_train, y_test, \n",
    "                                                     clf=grid_sgd, params=params_sgd, cv=2)\n",
    "\n",
    "        best_params = best.get_params()\n",
    "        grid_pipeline[name]['best_model'] = best\n",
    "        grid_pipeline[name]['best_params'] = best_params\n",
    "        grid_pipeline[name]['report'] = report\n",
    "\n",
    "        print(name)\n",
    "        for param, value in best_params.items():\n",
    "            if param in clf['grid'].keys():\n",
    "                print(f'{param}={value}')\n",
    "        print(print_report)\n",
    "        print(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не получилось, тут результаты все равно хуже чем с дефолтными параметрами, потому что даже на таком max_iter он не может зафититься..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью получается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75       148\n",
      "           0       0.75      0.79      0.77       171\n",
      "           1       0.87      0.78      0.82       123\n",
      "\n",
      "    accuracy                           0.78       442\n",
      "   macro avg       0.79      0.78      0.78       442\n",
      "weighted avg       0.78      0.78      0.78       442\n",
      "\n",
      "0.779170661715591\n"
     ]
    }
   ],
   "source": [
    "best_sgd = SGDClassifier(random_state=SEED)\n",
    "X, y = transform_data(data, '81')   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "_, print_report, report = fit_pred(X_train, X_test, y_train, y_test, clf=best_sgd)\n",
    "print(print_report)\n",
    "\n",
    "print(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверим влияние выбранного random_state\n",
    "\n",
    "1. на модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779170661715591 67\n",
      "0.761831913258592\n",
      "0.735995228156152\n"
     ]
    }
   ],
   "source": [
    "seeds = []\n",
    "\n",
    "for s in range(100):\n",
    "    sgd = SGDClassifier(random_state=s)\n",
    "    X, y = transform_data(data, '81')   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "    _, print_report, report = fit_pred(X_train, X_test, y_train, y_test, clf=sgd)\n",
    "\n",
    "    seeds.append((report['weighted avg']['f1-score']))\n",
    "    \n",
    "print(max(seeds), np.argmax(seeds))\n",
    "print(np.mean(seeds))\n",
    "print(min(seeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. на деление тест-трейн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876388345021732 94\n",
      "0.7381769095711054\n",
      "0.6793165866635282\n"
     ]
    }
   ],
   "source": [
    "seeds = []\n",
    "\n",
    "for s in range(100):\n",
    "    sgd = SGDClassifier(random_state=SEED)\n",
    "    X, y = transform_data(data, '81')   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=s, stratify=y)\n",
    "    _, print_report, report = fit_pred(X_train, X_test, y_train, y_test, clf=sgd)\n",
    "\n",
    "    seeds.append((report['weighted avg']['f1-score']))\n",
    "    \n",
    "print(max(seeds), np.argmax(seeds))\n",
    "print(np.mean(seeds))\n",
    "print(min(seeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Анна Полянская, 2020*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
