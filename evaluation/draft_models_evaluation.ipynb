{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text]\n",
    "    text = [c for c in allchars if c not in emoji.UNICODE_EMOJI]\n",
    "    return \"\".join(text)\n",
    "\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "def my_preprocess(text: str):\n",
    "    text = str(text)\n",
    "    text = give_emoji_free_text(text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_text = list(tokenize(text))\n",
    "    lemm = [morph.parse(i.text)[0].normal_form for i in tokenized_text]\n",
    "    words = [i for i in lemm if i not in stop and not i.isdigit() and len(i) > 2]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"LogisticRegression classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "\n",
    "def SDG(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(SGDClassifier(loss='hinge',\n",
    "                                              penalty='l2',\n",
    "                                              alpha=1e-3,\n",
    "                                              random_state=42,\n",
    "                                              max_iter=5,\n",
    "                                              tol=None)).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"SGDClassifier classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "def XGBoost(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(XGBClassifier()).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"XGBClassifier classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tf_idf_score(X_train, X_test):\n",
    "    labelToId = {'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1}\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for label in tqdm(X_train['—Ä–∞–∑–º–µ—Ç–∫–∞'].values):\n",
    "        y_train.append(labelToId[label])\n",
    "    for label in tqdm(X_test['—Ä–∞–∑–º–µ—Ç–∫–∞'].values):\n",
    "        y_test.append(labelToId[label])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(train.lemms.values)\n",
    "    X_train = vectorizer.fit_transform(X_train['lemms'].values)\n",
    "    X_test = vectorizer.transform(X_test['lemms'].values)\n",
    "\n",
    "    logreg(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    SDG(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc_vector(model, text):\n",
    "    lemmas = text.split()\n",
    "    lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
    "    vec = np.zeros((model.vector_size,))\n",
    "\n",
    "    for idx, lemma in enumerate(lemmas):\n",
    "        if lemma in model:\n",
    "            lemmas_vectors[idx] = model[lemma] / np.linalg.norm(model[lemma])\n",
    "    res = lemmas_vectors.mean(axis=0)\n",
    "    if np.all(np.isfinite(res)):\n",
    "        return res\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "\n",
    "\n",
    "def check_fasttext_score(X_train, X_test, pathToModelFolder=None):\n",
    "    labelToId = {'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1}\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for label in tqdm(X_train['—Ä–∞–∑–º–µ—Ç–∫–∞'].values):\n",
    "        y_train.append(labelToId[label])\n",
    "    for label in tqdm(X_test['—Ä–∞–∑–º–µ—Ç–∫–∞'].values):\n",
    "        y_test.append(labelToId[label])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # –∑–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å\n",
    "    if pathToModelFolder is None:\n",
    "        pathToModelFolder = 'araneum/araneum_none_fasttextcbow_300_5_2018.model'\n",
    "    else:\n",
    "        pathToModelFolder = pathToModelFolder\n",
    "    model = KeyedVectors.load(pathToModelFolder)\n",
    "\n",
    "    X_train = np.array([create_doc_vector(model, doc) for doc in X_train['lemms'].values])\n",
    "    X_test = np.array([create_doc_vector(model, doc) for doc in X_test['lemms'].values])\n",
    "\n",
    "    logreg(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    SDG(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–π—Ç–µ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ –∫–æ–ª–æ–Ω–∫—É \"lemms\", –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É –ª–µ–∂–∞—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∑–∞—Ç–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–∞ train –∏ test –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏ –≤—ã–∑—ã–≤–∞–π—Ç–µ –Ω–∞ –Ω–∏—Ö —Ñ—É–Ω–∫—Ü–∏–∏:\n",
    "\n",
    "### check_tf_idf_score(X_train, X_test)\n",
    "–≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç –∏ –≤—ã–¥–∞—Å—Ç —Å–∫–æ—Ä –¥–ª—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω—ã—Ö\n",
    "\n",
    "### check_fasttext_score(X_train, X_test, pathToModelFolder=None)\n",
    "–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ fasttext, –ø–æ—Å–ª–µ–¥–Ω–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ 4 —Ñ–∞–π–ª–∞, –ª–µ–∂–∞—â–∏—Ö –≤ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–≤–µ–Ω $araneum/araneum_none_fasttextcbow_300_5_2018.model$\n",
    "\n",
    "\n",
    "##### –°—Ç–æ–∏—Ç –∑–Ω–∞—Ç—å, —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç –≤—Ö–æ–¥—è—â—É—é —Ä–∞–∑–º–µ—Ç–∫—É –≤ —á–∏—Å–ª–∞ –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é:\n",
    "\n",
    "{'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1} - —Ç–æ –µ—Å—Ç—å –º–µ—Ç–∫–∏ skip, neutral –∏ speech —Å—á–∏—Ç–∞—é—Ç—Å—è –æ–¥–Ω–∏–º –∫–ª–∞—Å—Å–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–∞–ª–µ–µ –ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–µ–º —Ç–µ–∫—Å—Ç—ã (–∫–æ–¥ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –≤—ã—à–µ), —Ä–∞–∑–¥–µ–ª–∏–º –Ω–∞ test –∏ train, –∑–∞–∫–∏–Ω–µ–º –≤ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>—Ä–∞–∑–º–µ—Ç–∫–∞</th>\n",
       "      <th>—Ç–µ–∫—Å—Ç</th>\n",
       "      <th>–∫–æ–Ω—Ç–µ–∫—Å—Ç</th>\n",
       "      <th>community_id</th>\n",
       "      <th>community_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>speech</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>speech</td>\n",
       "      <td>–≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ!!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speech</td>\n",
       "      <td>–°—É–ø–µ—Ä! –ë–ª–∞–≥–æ–¥–∞—Ä—éüôè</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speech</td>\n",
       "      <td>–æ—Ñ–∏–≥–µ—Ç—å, —Å–ø–∞—Å–∏–±–æ!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É üíô</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 —Ä–∞–∑–º–µ—Ç–∫–∞                            —Ç–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç  \\\n",
       "0           0   speech                         –°–ø–∞—Å–∏–±–æ!     post   \n",
       "1           1   speech            –≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ!!     post   \n",
       "2           2   speech                –°—É–ø–µ—Ä! –ë–ª–∞–≥–æ–¥–∞—Ä—éüôè     post   \n",
       "3           3   speech                –æ—Ñ–∏–≥–µ—Ç—å, —Å–ø–∞—Å–∏–±–æ!     post   \n",
       "4           4   speech  —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É üíô     post   \n",
       "\n",
       "   community_id community_type  \n",
       "0             1       nontoxic  \n",
       "1             1       nontoxic  \n",
       "2             1       nontoxic  \n",
       "3             1       nontoxic  \n",
       "4             1       nontoxic  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"df.csv\")\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3524/3524 [00:15<00:00, 230.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>—Ä–∞–∑–º–µ—Ç–∫–∞</th>\n",
       "      <th>—Ç–µ–∫—Å—Ç</th>\n",
       "      <th>–∫–æ–Ω—Ç–µ–∫—Å—Ç</th>\n",
       "      <th>community_id</th>\n",
       "      <th>community_type</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>speech</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>speech</td>\n",
       "      <td>–≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ!!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>–≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–π</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speech</td>\n",
       "      <td>–°—É–ø–µ—Ä! –ë–ª–∞–≥–æ–¥–∞—Ä—éüôè</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>—Å—É–ø–µ—Ä –±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speech</td>\n",
       "      <td>–æ—Ñ–∏–≥–µ—Ç—å, —Å–ø–∞—Å–∏–±–æ!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>–æ—Ñ–∏–≥–µ—Ç—å —Å–ø–∞—Å–∏–±–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>speech</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É üíô</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–µ–ª–∞—Ç—å —Ä–∞–±–æ—Ç–∞</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 —Ä–∞–∑–º–µ—Ç–∫–∞                            —Ç–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç  \\\n",
       "0           0   speech                         –°–ø–∞—Å–∏–±–æ!     post   \n",
       "1           1   speech            –≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ!!     post   \n",
       "2           2   speech                –°—É–ø–µ—Ä! –ë–ª–∞–≥–æ–¥–∞—Ä—éüôè     post   \n",
       "3           3   speech                –æ—Ñ–∏–≥–µ—Ç—å, —Å–ø–∞—Å–∏–±–æ!     post   \n",
       "4           4   speech  —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É üíô     post   \n",
       "\n",
       "   community_id community_type                     lemms  \n",
       "0             1       nontoxic                   —Å–ø–∞—Å–∏–±–æ  \n",
       "1             1       nontoxic       –≤–∞—É —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–π  \n",
       "2             1       nontoxic         —Å—É–ø–µ—Ä –±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å  \n",
       "3             1       nontoxic           –æ—Ñ–∏–≥–µ—Ç—å —Å–ø–∞—Å–∏–±–æ  \n",
       "4             1       nontoxic  —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–µ–ª–∞—Ç—å —Ä–∞–±–æ—Ç–∞  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf = []\n",
    "for doc in tqdm(data['—Ç–µ–∫—Å—Ç'].values):\n",
    "    buf.append(my_preprocess(doc))\n",
    "\n",
    "data['lemms'] = buf\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2466/2466 [00:00<00:00, 551723.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1058/1058 [00:00<00:00, 550294.35it/s]\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier score: \n",
      "f1 score:  0.90046375065592\n",
      "precision:  0.9157519754228688\n",
      "recall:  0.9272211720226843\n",
      "accuracy score:  0.9272211720226843\n",
      "\n",
      "SGDClassifier classifier score: \n",
      "f1 score:  0.9090314880050534\n",
      "precision:  0.9201929176850433\n",
      "recall:  0.9310018903591682\n",
      "accuracy score:  0.9310018903591682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier classifier score: \n",
      "f1 score:  0.9136237963536673\n",
      "precision:  0.9077677932556515\n",
      "recall:  0.9253308128544423\n",
      "accuracy score:  0.9234404536862004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "check_tf_idf_score(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2466/2466 [00:00<00:00, 463444.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1058/1058 [00:00<00:00, 437630.54it/s]\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier score: \n",
      "f1 score:  0.9103134015700511\n",
      "precision:  0.9216918562938894\n",
      "recall:  0.9310018903591682\n",
      "accuracy score:  0.9310018903591682\n",
      "\n",
      "SGDClassifier classifier score: \n",
      "f1 score:  0.9121874665620431\n",
      "precision:  0.9304138795986622\n",
      "recall:  0.9328922495274102\n",
      "accuracy score:  0.9328922495274102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier classifier score: \n",
      "f1 score:  0.9287504555935558\n",
      "precision:  0.9336986240263773\n",
      "recall:  0.94234404536862\n",
      "accuracy score:  0.9376181474480151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "check_fasttext_score(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
