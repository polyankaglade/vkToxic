{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text]\n",
    "    text = [c for c in allchars if c not in emoji.UNICODE_EMOJI]\n",
    "    return \"\".join(text)\n",
    "\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "def my_preprocess(text: str):\n",
    "    text = str(text)\n",
    "    text = give_emoji_free_text(text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_text = list(tokenize(text))\n",
    "    lemm = [morph.parse(i.text)[0].normal_form for i in tokenized_text]\n",
    "    words = [i for i in lemm if i not in stop and not i.isdigit() and len(i) > 2]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"LogisticRegression classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "\n",
    "def SDG(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(SGDClassifier(loss='hinge',\n",
    "                                              penalty='l2',\n",
    "                                              alpha=1e-3,\n",
    "                                              random_state=42,\n",
    "                                              max_iter=5,\n",
    "                                              tol=None)).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"SGDClassifier classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "def XGBoost(X_train, X_test, y_train, y_test):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_test = pd.get_dummies(y_test)\n",
    "    clf = MultiOutputClassifier(XGBClassifier()).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"XGBClassifier classifier score: \")\n",
    "    print(\"f1 score: \", f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"precision: \", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"accuracy score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tf_idf_score(X_train, X_test):\n",
    "    labelToId = {'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1}\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for label in tqdm(X_train['разметка'].values):\n",
    "        y_train.append(labelToId[label])\n",
    "    for label in tqdm(X_test['разметка'].values):\n",
    "        y_test.append(labelToId[label])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(train.lemms.values)\n",
    "    X_train = vectorizer.fit_transform(X_train['lemms'].values)\n",
    "    X_test = vectorizer.transform(X_test['lemms'].values)\n",
    "\n",
    "    logreg(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    SDG(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc_vector(model, text):\n",
    "    lemmas = text.split()\n",
    "    lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
    "    vec = np.zeros((model.vector_size,))\n",
    "\n",
    "    for idx, lemma in enumerate(lemmas):\n",
    "        if lemma in model:\n",
    "            lemmas_vectors[idx] = model[lemma] / np.linalg.norm(model[lemma])\n",
    "    res = lemmas_vectors.mean(axis=0)\n",
    "    if np.all(np.isfinite(res)):\n",
    "        return res\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "\n",
    "\n",
    "def check_fasttext_score(X_train, X_test, pathToModelFolder=None):\n",
    "    labelToId = {'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1}\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for label in tqdm(X_train['разметка'].values):\n",
    "        y_train.append(labelToId[label])\n",
    "    for label in tqdm(X_test['разметка'].values):\n",
    "        y_test.append(labelToId[label])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # загрузим модель\n",
    "    if pathToModelFolder is None:\n",
    "        pathToModelFolder = 'araneum/araneum_none_fasttextcbow_300_5_2018.model'\n",
    "    else:\n",
    "        pathToModelFolder = pathToModelFolder\n",
    "    model = KeyedVectors.load(pathToModelFolder)\n",
    "\n",
    "    X_train = np.array([create_doc_vector(model, doc) for doc in X_train['lemms'].values])\n",
    "    X_test = np.array([create_doc_vector(model, doc) for doc in X_test['lemms'].values])\n",
    "\n",
    "    logreg(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    SDG(X_train, X_test, y_train, y_test)\n",
    "    print()\n",
    "    XGBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создайте в датафрейме колонку \"lemms\", в котором буду лежать предобработанные предложения, затем разделите датафрейм на train и test подмножества и вызывайте на них функции:\n",
    "\n",
    "### check_tf_idf_score(X_train, X_test)\n",
    "векторизует и выдаст скор для переданных даных\n",
    "\n",
    "### check_fasttext_score(X_train, X_test, pathToModelFolder=None)\n",
    "использует усреднённые вектора fasttext, последним аргументом передаётся путь к модели (необходимо 4 файла, лежащих в одной папке), по умолчанию равен $araneum/araneum_none_fasttextcbow_300_5_2018.model$\n",
    "\n",
    "\n",
    "##### Стоит знать, что внутри функции преобразуют входящую разметку в числа по соответствию:\n",
    "\n",
    "{'negative': 0, 'neutral': 1, 'positive': 2, 'skip': 1, 'speech': 1} - то есть метки skip, neutral и speech считаются одним классом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Далее пример, предобработаем тексты (код препроцессинга выше), разделим на test и train, закинем в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>разметка</th>\n",
       "      <th>текст</th>\n",
       "      <th>контекст</th>\n",
       "      <th>community_id</th>\n",
       "      <th>community_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>speech</td>\n",
       "      <td>Спасибо!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>speech</td>\n",
       "      <td>вау спасибо большое!!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speech</td>\n",
       "      <td>Супер! Благодарю🙏</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speech</td>\n",
       "      <td>офигеть, спасибо!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>speech</td>\n",
       "      <td>спасибо за проделанную работу 💙</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 разметка                            текст контекст  \\\n",
       "0           0   speech                         Спасибо!     post   \n",
       "1           1   speech            вау спасибо большое!!     post   \n",
       "2           2   speech                Супер! Благодарю🙏     post   \n",
       "3           3   speech                офигеть, спасибо!     post   \n",
       "4           4   speech  спасибо за проделанную работу 💙     post   \n",
       "\n",
       "   community_id community_type  \n",
       "0             1       nontoxic  \n",
       "1             1       nontoxic  \n",
       "2             1       nontoxic  \n",
       "3             1       nontoxic  \n",
       "4             1       nontoxic  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"df.csv\")\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3524/3524 [00:15<00:00, 230.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>разметка</th>\n",
       "      <th>текст</th>\n",
       "      <th>контекст</th>\n",
       "      <th>community_id</th>\n",
       "      <th>community_type</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>speech</td>\n",
       "      <td>Спасибо!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>спасибо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>speech</td>\n",
       "      <td>вау спасибо большое!!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>вау спасибо большой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speech</td>\n",
       "      <td>Супер! Благодарю🙏</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>супер благодарить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>speech</td>\n",
       "      <td>офигеть, спасибо!</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>офигеть спасибо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>speech</td>\n",
       "      <td>спасибо за проделанную работу 💙</td>\n",
       "      <td>post</td>\n",
       "      <td>1</td>\n",
       "      <td>nontoxic</td>\n",
       "      <td>спасибо проделать работа</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 разметка                            текст контекст  \\\n",
       "0           0   speech                         Спасибо!     post   \n",
       "1           1   speech            вау спасибо большое!!     post   \n",
       "2           2   speech                Супер! Благодарю🙏     post   \n",
       "3           3   speech                офигеть, спасибо!     post   \n",
       "4           4   speech  спасибо за проделанную работу 💙     post   \n",
       "\n",
       "   community_id community_type                     lemms  \n",
       "0             1       nontoxic                   спасибо  \n",
       "1             1       nontoxic       вау спасибо большой  \n",
       "2             1       nontoxic         супер благодарить  \n",
       "3             1       nontoxic           офигеть спасибо  \n",
       "4             1       nontoxic  спасибо проделать работа  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf = []\n",
    "for doc in tqdm(data['текст'].values):\n",
    "    buf.append(my_preprocess(doc))\n",
    "\n",
    "data['lemms'] = buf\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2466/2466 [00:00<00:00, 551723.14it/s]\n",
      "100%|██████████| 1058/1058 [00:00<00:00, 550294.35it/s]\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier score: \n",
      "f1 score:  0.90046375065592\n",
      "precision:  0.9157519754228688\n",
      "recall:  0.9272211720226843\n",
      "accuracy score:  0.9272211720226843\n",
      "\n",
      "SGDClassifier classifier score: \n",
      "f1 score:  0.9090314880050534\n",
      "precision:  0.9201929176850433\n",
      "recall:  0.9310018903591682\n",
      "accuracy score:  0.9310018903591682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier classifier score: \n",
      "f1 score:  0.9136237963536673\n",
      "precision:  0.9077677932556515\n",
      "recall:  0.9253308128544423\n",
      "accuracy score:  0.9234404536862004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "check_tf_idf_score(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2466/2466 [00:00<00:00, 463444.47it/s]\n",
      "100%|██████████| 1058/1058 [00:00<00:00, 437630.54it/s]\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier score: \n",
      "f1 score:  0.9103134015700511\n",
      "precision:  0.9216918562938894\n",
      "recall:  0.9310018903591682\n",
      "accuracy score:  0.9310018903591682\n",
      "\n",
      "SGDClassifier classifier score: \n",
      "f1 score:  0.9121874665620431\n",
      "precision:  0.9304138795986622\n",
      "recall:  0.9328922495274102\n",
      "accuracy score:  0.9328922495274102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier classifier score: \n",
      "f1 score:  0.9287504555935558\n",
      "precision:  0.9336986240263773\n",
      "recall:  0.94234404536862\n",
      "accuracy score:  0.9376181474480151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/koteuka/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "check_fasttext_score(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
