{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем мета-файл (дважды, потому что один из них будем менять, а второй референсить). Можно было бы сделать более логично, но я почему-то решила так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../preprocess/meta.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "with open('../preprocess/meta.json', 'r') as f:\n",
    "    original_meta = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем файл с обработанными данными, заменяем все пустые ячейки на `none`. Откуда пустые ячейки? Они возникают в вариантах препроцессинга, где используется удаление стоп-слов и/или удаление эмоджи (например, когда комментарий изначально состоял только из эмоджи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, index_col=0, sep='\\t')\n",
    "    print(f'loaded from {filepath}')\n",
    "    print(df['разметка'].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from ../Data/Test_data_preprocessed.tsv\n",
      "negative    436\n",
      "positive    367\n",
      "neutral     321\n",
      "speech      189\n",
      "Name: разметка, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = load_data('../Data/Test_data_preprocessed.tsv')\n",
    "data.fillna('none',  inplace=True)\n",
    "assert data.isnull().values.any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для кодирования разметки в числовые классы. **NB**: классы `neutral` и `speech` объединяются (чтобы было больше данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labeling(label):\n",
    "    if label == 'negative':\n",
    "        label_id = -1\n",
    "    elif label == 'neutral':\n",
    "        label_id = 0\n",
    "    elif label == 'positive':\n",
    "        label_id = 1\n",
    "    elif label == 'speech':\n",
    "        label_id = 0\n",
    "        \n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая обычная tf-idf векторизация, т.к. данных мало и объем вокабуляра не превышает 5к слов. Для ускорения работы используется `analyzer=str.split`, чтобы отключить встроенную токенизацию (т.к. все наши данные и так токенизированны через пробел)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, col_name):\n",
    "    y = data['разметка'].apply(encode_labeling)\n",
    "    \n",
    "    corpus = data[col_name]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(analyzer=str.split)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1313, 4335)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_id = str(0)\n",
    "X, y = transform_data(data, prep_id)\n",
    "print(X.shape)\n",
    "original_meta[prep_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы решили сравнить 5 алгоритмов класификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pred(X_train, X_test, y_train, y_test, clf=None):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print_report = classification_report(y_test, pred)\n",
    "    report = classification_report(y_test, pred, output_dict=True)\n",
    "    #print(print_report)\n",
    "    return pred, print_report, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гридсерч используется ниже, уже после определения наиболее удачной модели и препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_pred(X_train, X_test, y_train, y_test, clf=None, params={}, cv=3):\n",
    "    grid = GridSearchCV(clf, params)\n",
    "    grid.fit(X_train, y_train)\n",
    "    #print(grid.best_params_)\n",
    "    \n",
    "    best = g_forest.best_estimator_\n",
    "    \n",
    "    best.fit(X_train, y_train)\n",
    "    pred = best.predict(X_test)\n",
    "    print_report = classification_report(y_test, pred)\n",
    "    report = classification_report(y_test, pred, output_dict=True)\n",
    "    #print(print_report)\n",
    "    \n",
    "    return best, pred, print_report, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама функция которая обучает все модели и возвращает отчет с метриками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(X_train, X_test, y_train, y_test, log=False):\n",
    "    \n",
    "    clf_logreg = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "    clf_sgd = SGDClassifier(random_state=SEED)\n",
    "    clf_forest = RandomForestClassifier(random_state=SEED)\n",
    "    clf_bayes = MultinomialNB()\n",
    "    clf_xgboost = XGBClassifier()\n",
    "\n",
    "    clfs = {'logreg': {'model': clf_logreg, 'report': {}},\n",
    "            'sgd': {'model': clf_sgd, 'report': {}},\n",
    "            'forest': {'model': clf_forest, 'report': {}}, \n",
    "            'bayes':  {'model': clf_bayes,  'report': {}},\n",
    "            'xgboost':  {'model': clf_xgboost,  'report': {}}\n",
    "           }\n",
    "    \n",
    "    for name, clf in clfs.items():\n",
    "        model = clf['model']\n",
    "        _, print_report, report = fit_pred(X_train, X_test, y_train, y_test, clf=model)\n",
    "        clfs[name]['report'] = report\n",
    "        clfs[name]['pred'] = pred\n",
    "        \n",
    "        if log:\n",
    "            print(name.upper())\n",
    "            print(print_report)\n",
    "        \n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования на данных, заданных выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGREG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.56      0.62       131\n",
      "           0       0.59      0.76      0.66       153\n",
      "           1       0.82      0.68      0.74       110\n",
      "\n",
      "    accuracy                           0.67       394\n",
      "   macro avg       0.70      0.67      0.67       394\n",
      "weighted avg       0.69      0.67      0.67       394\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.64      0.66       131\n",
      "           0       0.64      0.70      0.67       153\n",
      "           1       0.79      0.75      0.77       110\n",
      "\n",
      "    accuracy                           0.69       394\n",
      "   macro avg       0.70      0.70      0.70       394\n",
      "weighted avg       0.70      0.69      0.69       394\n",
      "\n",
      "FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.47      0.56       131\n",
      "           0       0.56      0.74      0.64       153\n",
      "           1       0.67      0.66      0.67       110\n",
      "\n",
      "    accuracy                           0.63       394\n",
      "   macro avg       0.65      0.62      0.62       394\n",
      "weighted avg       0.64      0.63      0.62       394\n",
      "\n",
      "BAYES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.57      0.65       131\n",
      "           0       0.55      0.88      0.68       153\n",
      "           1       0.90      0.43      0.58       110\n",
      "\n",
      "    accuracy                           0.65       394\n",
      "   macro avg       0.74      0.63      0.64       394\n",
      "weighted avg       0.72      0.65      0.64       394\n",
      "\n",
      "XGBOOST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.63      0.64       131\n",
      "           0       0.62      0.68      0.65       153\n",
      "           1       0.73      0.65      0.69       110\n",
      "\n",
      "    accuracy                           0.66       394\n",
      "   macro avg       0.67      0.66      0.66       394\n",
      "weighted avg       0.66      0.66      0.66       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "report = try_models(X_train, X_test, y_train, y_test, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted avg f1-score\n",
      "\n",
      "LOGREG\t0.6704129036937323\n",
      "SGD\t0.6935621439388309\n",
      "FOREST\t0.6225348941498408\n",
      "BAYES\t0.6416431412385212\n",
      "XGBOOST\t0.6579754002342835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('weighted avg f1-score\\n')\n",
    "\n",
    "for name, clf in report.items():\n",
    "    print(f\"{name.upper()}\\t{clf['report']['weighted avg']['f1-score']}\")\n",
    "          \n",
    "original_meta[prep_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей с базовыми параметрами и всех препроцессингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь обучается и замеряется кач-во 960 моделей (за ~8 минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ed0d1c23324ec8b82782cdc4417b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for m_id, m in tqdm(meta.items()):\n",
    "    X, y = transform_data(data, m_id)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "    \n",
    "    reports = try_models(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    meta[m_id]['reports'] = reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики выбрали weighted average f1-score, вырезаем только его, чтобы можно было внимательнее посмотреть на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weighted_fs = []\n",
    "preps = []\n",
    "models = []\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    #print(original_meta[m_id])\n",
    "    \n",
    "    for name, clf in m['reports'].items():\n",
    "        score = clf['report']['weighted avg']['f1-score']\n",
    "        \n",
    "        weighted_fs.append(score)\n",
    "        preps.append(m_id)\n",
    "        models.append(name)\n",
    "        #print(f\"{name.upper()}\\t{score}\")\n",
    "        \n",
    "    #print('\\n===========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все варианты с метрикой выше `0.73`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\tsgd\t0.7460955019649301\n",
      "151\tsgd\t0.7445162556013984\n",
      "182\tsgd\t0.7437483242722889\n",
      "117\tsgd\t0.7417101203331323\n",
      "183\tsgd\t0.7416138595677357\n",
      "97\tsgd\t0.7410744344834481\n",
      "176\tsgd\t0.7393389329607376\n",
      "150\tsgd\t0.7386623809291071\n",
      "87\tsgd\t0.7364395418749176\n",
      "181\tsgd\t0.7363485156033366\n",
      "113\tsgd\t0.7362855632878136\n",
      "83\tforest\t0.7359792063880859\n",
      "119\tsgd\t0.7343673197510162\n",
      "112\tsgd\t0.7340846174058158\n",
      "149\tsgd\t0.7340678003956387\n",
      "149\tforest\t0.7339013202490693\n",
      "83\tsgd\t0.7338495227082659\n",
      "148\tsgd\t0.7338127762128792\n",
      "135\tsgd\t0.7335916200738946\n",
      "151\tlogreg\t0.7334049279113447\n",
      "183\tlogreg\t0.7334049279113447\n",
      "119\tlogreg\t0.7334049279113447\n",
      "145\tsgd\t0.7333381483000007\n",
      "184\tsgd\t0.7323146816768177\n",
      "116\tsgd\t0.7318931263033746\n",
      "167\tsgd\t0.731640052754087\n",
      "54\tsgd\t0.7316054793737272\n",
      "119\tforest\t0.7312113465824605\n",
      "103\tsgd\t0.7311894399955903\n",
      "5\tsgd\t0.7310752132005299\n",
      "21\tsgd\t0.7310752132005299\n",
      "51\tlogreg\t0.730983563349178\n",
      "83\tlogreg\t0.730983563349178\n"
     ]
    }
   ],
   "source": [
    "top_prep = []\n",
    "top_model = []\n",
    "\n",
    "for i in np.argsort(weighted_fs)[::-1]:\n",
    "    if weighted_fs[i] < 0.73:\n",
    "        break\n",
    "    top_prep.append(preps[i])\n",
    "    top_model.append(models[i])\n",
    "    print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разброс значений для наилучшего алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\tsgd\t0.7460955019649301\n",
      "151\tsgd\t0.7445162556013984\n",
      "182\tsgd\t0.7437483242722889\n",
      "117\tsgd\t0.7417101203331323\n",
      "183\tsgd\t0.7416138595677357\n",
      "97\tsgd\t0.7410744344834481\n",
      "176\tsgd\t0.7393389329607376\n",
      "150\tsgd\t0.7386623809291071\n",
      "87\tsgd\t0.7364395418749176\n",
      "181\tsgd\t0.7363485156033366\n",
      "113\tsgd\t0.7362855632878136\n",
      "119\tsgd\t0.7343673197510162\n",
      "112\tsgd\t0.7340846174058158\n",
      "149\tsgd\t0.7340678003956387\n",
      "83\tsgd\t0.7338495227082659\n",
      "148\tsgd\t0.7338127762128792\n",
      "135\tsgd\t0.7335916200738946\n",
      "145\tsgd\t0.7333381483000007\n",
      "184\tsgd\t0.7323146816768177\n",
      "116\tsgd\t0.7318931263033746\n",
      "167\tsgd\t0.731640052754087\n",
      "54\tsgd\t0.7316054793737272\n",
      "103\tsgd\t0.7311894399955903\n",
      "5\tsgd\t0.7310752132005299\n",
      "21\tsgd\t0.7310752132005299\n",
      "53\tsgd\t0.7291973418044168\n",
      "118\tsgd\t0.7289064666228796\n",
      "33\tsgd\t0.7281863707333714\n",
      "161\tsgd\t0.7281350042485091\n",
      "144\tsgd\t0.7266779819764344\n",
      "133\tsgd\t0.7264029683632327\n",
      "101\tsgd\t0.7263424585141931\n",
      "164\tsgd\t0.7262493687767182\n",
      "180\tsgd\t0.7261169771682464\n",
      "177\tsgd\t0.7259680872317501\n",
      "178\tsgd\t0.7258007141477278\n",
      "120\tsgd\t0.7244147408495858\n",
      "166\tsgd\t0.7241632442784244\n",
      "85\tsgd\t0.7240782551682334\n",
      "96\tsgd\t0.7239811120635149\n",
      "86\tsgd\t0.7238730458539218\n",
      "55\tsgd\t0.723861079876151\n",
      "84\tsgd\t0.7237997822361638\n",
      "65\tsgd\t0.7235103210202127\n",
      "125\tsgd\t0.7220943613602517\n",
      "124\tsgd\t0.7220928802880807\n",
      "152\tsgd\t0.7220562514568019\n",
      "127\tsgd\t0.7217322936443189\n",
      "100\tsgd\t0.7212748614370444\n",
      "49\tsgd\t0.7211174086176507\n",
      "81\tsgd\t0.7210743278314352\n",
      "51\tsgd\t0.7210408578583685\n",
      "115\tsgd\t0.7209130495447053\n",
      "19\tsgd\t0.7207006191777764\n",
      "35\tsgd\t0.7207006191777764\n",
      "3\tsgd\t0.7207006191777764\n",
      "17\tsgd\t0.7201680979391412\n",
      "1\tsgd\t0.7201680979391412\n",
      "82\tsgd\t0.7201077383010073\n",
      "132\tsgd\t0.7190804187254365\n",
      "160\tsgd\t0.7187321093845965\n",
      "165\tsgd\t0.7186642357662771\n",
      "128\tsgd\t0.7181047143593072\n",
      "50\tsgd\t0.7175333604477321\n",
      "159\tsgd\t0.7166942395034833\n",
      "52\tsgd\t0.7163690957022196\n",
      "23\tsgd\t0.7160507504903105\n",
      "7\tsgd\t0.7160507504903105\n",
      "67\tsgd\t0.7156138805066264\n",
      "146\tsgd\t0.7154340574167537\n",
      "114\tsgd\t0.7152922239063548\n",
      "158\tsgd\t0.7145265393689773\n",
      "188\tsgd\t0.714402327466068\n",
      "69\tsgd\t0.7140380090379433\n",
      "162\tsgd\t0.7122701951526555\n",
      "156\tsgd\t0.7118329132796136\n",
      "189\tsgd\t0.7113607543219812\n",
      "39\tsgd\t0.7110583185614912\n",
      "179\tsgd\t0.7107654077954323\n",
      "185\tsgd\t0.7096597868607865\n",
      "80\tsgd\t0.7089860007179024\n",
      "60\tsgd\t0.7088963386284641\n",
      "48\tsgd\t0.7088596519920276\n",
      "134\tsgd\t0.708833699432021\n",
      "37\tsgd\t0.708832957027392\n",
      "147\tsgd\t0.708038462846379\n",
      "99\tsgd\t0.7077923402684645\n",
      "131\tsgd\t0.7077923402684645\n",
      "130\tsgd\t0.7074282258970369\n",
      "98\tsgd\t0.7074282258970369\n",
      "121\tsgd\t0.7073348082265877\n",
      "126\tsgd\t0.7070246947447935\n",
      "191\tsgd\t0.7068954395687406\n",
      "186\tsgd\t0.7063736847842272\n",
      "157\tsgd\t0.704269657470123\n",
      "88\tsgd\t0.7040481817444393\n",
      "105\tsgd\t0.7035851401132243\n",
      "58\tsgd\t0.7035497128447511\n",
      "90\tsgd\t0.7028818839323014\n",
      "153\tsgd\t0.7021765257056508\n",
      "190\tsgd\t0.7020309188802917\n",
      "56\tsgd\t0.7016738253286476\n",
      "154\tsgd\t0.7012962661253451\n",
      "92\tsgd\t0.7012133743209747\n",
      "122\tsgd\t0.7011148839747003\n",
      "89\tsgd\t0.6991091862219115\n",
      "63\tsgd\t0.6990805465236779\n",
      "6\tsgd\t0.6986395825716352\n",
      "22\tsgd\t0.6986395825716352\n",
      "71\tsgd\t0.6985716082817625\n",
      "64\tsgd\t0.695718386786353\n",
      "163\tsgd\t0.6953848784747211\n",
      "61\tsgd\t0.694152090216429\n",
      "57\tsgd\t0.6940688288100009\n",
      "93\tsgd\t0.6938318137591263\n",
      "38\tsgd\t0.6937605875289552\n",
      "0\tsgd\t0.6935621439388309\n",
      "16\tsgd\t0.6935621439388309\n",
      "36\tsgd\t0.6933567281097455\n",
      "175\tsgd\t0.6927667189920657\n",
      "62\tsgd\t0.6919381332767047\n",
      "91\tsgd\t0.6919047914927988\n",
      "123\tsgd\t0.6917100755488895\n",
      "32\tsgd\t0.6906083620229141\n",
      "143\tsgd\t0.690050508519025\n",
      "94\tsgd\t0.6891292755278663\n",
      "155\tsgd\t0.6888029479138518\n",
      "141\tsgd\t0.6886333665165131\n",
      "137\tsgd\t0.6870692795924991\n",
      "95\tsgd\t0.6865331331693858\n",
      "187\tsgd\t0.6864546711267683\n",
      "70\tsgd\t0.6859920663457612\n",
      "4\tsgd\t0.6859751195957076\n",
      "20\tsgd\t0.6859751195957076\n",
      "109\tsgd\t0.6858394411487192\n",
      "43\tsgd\t0.6857790364725765\n",
      "11\tsgd\t0.6857790364725765\n",
      "27\tsgd\t0.6857790364725765\n",
      "29\tsgd\t0.6855435345518951\n",
      "13\tsgd\t0.6855435345518951\n",
      "173\tsgd\t0.6854481685931643\n",
      "169\tsgd\t0.6851247383465332\n",
      "111\tsgd\t0.6848645158546309\n",
      "41\tsgd\t0.6834114630434427\n",
      "66\tsgd\t0.681792641688984\n",
      "102\tsgd\t0.6809737090055068\n",
      "34\tsgd\t0.679664028896304\n",
      "2\tsgd\t0.679664028896304\n",
      "18\tsgd\t0.679664028896304\n",
      "68\tsgd\t0.6785191455917827\n",
      "15\tsgd\t0.6779086992440713\n",
      "31\tsgd\t0.6779086992440713\n",
      "79\tsgd\t0.6775071439673573\n",
      "77\tsgd\t0.6772392386184138\n",
      "139\tsgd\t0.6771839094752199\n",
      "107\tsgd\t0.6771839094752199\n",
      "59\tsgd\t0.6771219050261035\n",
      "75\tsgd\t0.6753641930545484\n",
      "47\tsgd\t0.675310845190685\n",
      "171\tsgd\t0.6744704570791528\n",
      "9\tsgd\t0.6742278038465848\n",
      "25\tsgd\t0.6742278038465848\n",
      "45\tsgd\t0.6724566914403237\n",
      "10\tsgd\t0.6666716266324195\n",
      "42\tsgd\t0.6666716266324195\n",
      "26\tsgd\t0.6666716266324195\n",
      "74\tsgd\t0.6650724596074195\n",
      "78\tsgd\t0.6643306218300167\n",
      "24\tsgd\t0.6641757421447466\n",
      "8\tsgd\t0.6641757421447466\n",
      "73\tsgd\t0.6625567854211708\n",
      "46\tsgd\t0.661917256664553\n",
      "30\tsgd\t0.6617492913178192\n",
      "14\tsgd\t0.6617492913178192\n",
      "44\tsgd\t0.6607257310902432\n",
      "28\tsgd\t0.6595824082221516\n",
      "12\tsgd\t0.6595824082221516\n",
      "104\tsgd\t0.6590939351374299\n",
      "40\tsgd\t0.6575146340501531\n",
      "168\tsgd\t0.6523605745864759\n",
      "72\tsgd\t0.650451867185138\n",
      "172\tsgd\t0.64840912895621\n",
      "76\tsgd\t0.6469674588227722\n",
      "136\tsgd\t0.6468439403276435\n",
      "110\tsgd\t0.6439538147977234\n",
      "140\tsgd\t0.6435292979656182\n",
      "174\tsgd\t0.6411850543182377\n",
      "142\tsgd\t0.6410041241116298\n",
      "108\tsgd\t0.6409431118299438\n",
      "170\tsgd\t0.6309129372133526\n",
      "138\tsgd\t0.6282519684955415\n",
      "106\tsgd\t0.6282519684955415\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(weighted_fs)[::-1]:\n",
    "    if models[i] == 'sgd':\n",
    "        print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что лучший результат дает препроцессинг с удалением именованных сущностей, заменой мата на плейсходер и удалением пунктуации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'yes',\n",
       " 'ner_processing': 'del',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'no',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['129']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А худший результат получается при удалении всего, что можно, и без нормализации (нет ни лемматизации, ни замены мата):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'yes',\n",
       " 'ner_processing': 'del',\n",
       " 'lemmatization': 'no',\n",
       " 'stopwords_deletion': 'yes',\n",
       " 'emojis_processing': 'del',\n",
       " 'vulgar_processing': 'no'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['138']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим внимательнее на варианты с результатами `> 0.73`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgd', 25), ('logreg', 5), ('forest', 3)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_models = Counter(top_model).most_common()\n",
    "c_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('83', 3),\n",
       " ('119', 3),\n",
       " ('151', 2),\n",
       " ('183', 2),\n",
       " ('149', 2),\n",
       " ('129', 1),\n",
       " ('182', 1),\n",
       " ('117', 1),\n",
       " ('97', 1),\n",
       " ('176', 1),\n",
       " ('150', 1),\n",
       " ('87', 1),\n",
       " ('181', 1),\n",
       " ('113', 1),\n",
       " ('112', 1),\n",
       " ('148', 1),\n",
       " ('135', 1),\n",
       " ('145', 1),\n",
       " ('184', 1),\n",
       " ('116', 1),\n",
       " ('167', 1),\n",
       " ('54', 1),\n",
       " ('103', 1),\n",
       " ('5', 1),\n",
       " ('21', 1),\n",
       " ('51', 1)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(top_prep).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'no',\n",
       " 'ner_processing': 'replace',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'del',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['83']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punctuation_deletion': 'yes',\n",
       " 'ner_processing': 'no',\n",
       " 'lemmatization': 'yes',\n",
       " 'stopwords_deletion': 'no',\n",
       " 'emojis_processing': 'label',\n",
       " 'vulgar_processing': 'yes'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_meta['119']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего изучения на всякий случай сохраняем все результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_meta = {}\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    json_meta[m_id] = {'prep': {},\n",
    "                       'reports': {'logreg': {},\n",
    "                                   'sgd': {},\n",
    "                                   'forest': {}, \n",
    "                                   'bayes':  {},\n",
    "                                   'xgboost':  {}}\n",
    "                      }\n",
    "\n",
    "for m_id, m in meta.items():\n",
    "    json_meta[m_id]['prep'] = original_meta[m_id]\n",
    "    for name, clf in m['reports'].items():\n",
    "        json_meta[m_id]['reports'][name] = clf['report']\n",
    "\n",
    "with open('compare.json', 'w') as f:\n",
    "    json.dump(json_meta, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров\n",
    "\n",
    "В кач-ве данных возьмем препроцессинги, показавшие наилучший результат для каждой из 3 моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\tsgd\t0.7460955019649301\n",
      "151\tlogreg\t0.7334049279113447\n",
      "83\tforest\t0.7359792063880859\n"
     ]
    }
   ],
   "source": [
    "for m in c_models:\n",
    "    for i in np.argsort(weighted_fs)[::-1]:\n",
    "        if models[i] == m[0]:\n",
    "            print(f'{preps[i]}\\t{models[i]}\\t{weighted_fs[i]}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logreg = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "grid_sgd = SGDClassifier(random_state=SEED)\n",
    "grid_forest = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "grid_pipeline = {\n",
    "    'sgd': {'model': grid_sgd, 'best_model': None, 'best_params': {}, 'report': {}, 'grid':{\n",
    "        \n",
    "    }},\n",
    "    'logreg': {'model': grid_logreg, 'best_model': None, 'best_params': {}, 'report': {}, 'grid':{\n",
    "        \n",
    "    }},\n",
    "    'forest': {'model': grid_forest, 'best_model': None, 'best_params': {}, 'report': {}, 'grid':{\n",
    "        \n",
    "    }},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, None was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-73d2fe768b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-216-741fa1e5d164>\u001b[0m in \u001b[0;36mgrid_pred\u001b[1;34m(X_train, X_test, y_train, y_test, clf, params, cv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrid_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(grid.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[1;32m--> 655\u001b[1;33m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    474\u001b[0m                                                           str):\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[1;32m--> 403\u001b[1;33m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, None was passed"
     ]
    }
   ],
   "source": [
    "best, pred, print_report, report = grid_pred(X_train, X_test, y_train, y_test, clf=None, params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Анна Полянская, 2020*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
